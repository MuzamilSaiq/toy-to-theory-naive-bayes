# toy-to-theory-naive-bayes
A pedagogical walkthrough of Naive Bayes—from toy intuition to full categorical implementation. Built from scratch to teach probabilistic modeling, conditional independence, and classifier design. It starts with a toy model (think coin flips and smoking habits) and scales up to a full categorical implementation.

### What's Inside
- A toy classifier based on conditional probability
- A full Naive Bayes model for categorical features
- Class-based predictions with confidence scores
- Commentary that connects math to intuition

### Requirements
- Python 3.x
- pandas
   
### References
- Freund, J.E. (1973). *Introduction to Probability*  
- Dataset adapted from the [UCI Mushroom Dataset](https://archive.ics.uci.edu/ml/datasets/Mushroom)
- Kolmogorov, *Foundations of the Theory of Probability*

## Attribution Required

This notebook is a pedagogical artifact designed to teach Naive Bayes through intuitive modeling. If you reuse, remix, or fork this work—especially its structure, commentary, or teaching arc—please credit the original author.

Suggested attribution:
> Inspired by toy-to-theory-naive-bayes: A Pedagogical Walkthrough of Naive Bayes by Muzamil.
